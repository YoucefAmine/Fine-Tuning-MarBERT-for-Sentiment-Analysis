{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZabWfNeygW08",
        "outputId": "221e2601-1b31-4419-a07e-2f0ba3e0fc4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "Fri Jun 10 15:22:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8    15W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    !nvidia-smi\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing the libraries needed** "
      ],
      "metadata": {
        "id": "ZHbf60yFFvxn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4A8GC7qgdQ1",
        "outputId": "0817f145-8fa6-4a25-e726-e97a6c684701"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.14-py3-none-any.whl (126 kB)\n",
            "\u001b[K     |████████████████████████████████| 126 kB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from pyarabic) (1.15.0)\n",
            "Installing collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.14\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 15.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=ad7285bcc10990b894ab1be7949d3210dd3b7bb6dd99ae5d7786ae30a3bbbd67\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pystemmer\n",
            "  Downloading PyStemmer-2.0.1.tar.gz (559 kB)\n",
            "\u001b[K     |████████████████████████████████| 559 kB 14.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pystemmer\n",
            "  Building wheel for pystemmer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pystemmer: filename=PyStemmer-2.0.1-cp37-cp37m-linux_x86_64.whl size=425684 sha256=74bca66e15275ac733fa8ba882c1c3437ab1e9a3b4b29a28aeb45d36d1d1dba3\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6d/40/0d17a498c5009922dbb3ddaca3d3652387ba94cc96142001f0\n",
            "Successfully built pystemmer\n",
            "Installing collected packages: pystemmer\n",
            "Successfully installed pystemmer-2.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna==2.3.0\n",
            "  Downloading optuna-2.3.0.tar.gz (258 kB)\n",
            "\u001b[K     |████████████████████████████████| 258 kB 14.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (1.21.6)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (4.64.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (1.4.36)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (21.3)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 11.2 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 75.4 MB/s \n",
            "\u001b[?25hCollecting cmaes>=0.6.0\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from optuna==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna==2.3.0) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.3.0) (4.11.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna==2.3.0) (1.1.2)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna==2.3.0) (5.7.1)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 75.7 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.3.0) (3.3.0)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna==2.3.0) (3.13)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (4.2.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna==2.3.0) (21.4.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna==2.3.0) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna==2.3.0) (2.0.1)\n",
            "Building wheels for collected packages: optuna, pyperclip\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-py3-none-any.whl size=359772 sha256=d4e78ff9980ee309d23f08594bd36e299c9740b3b81f1f655ab729ef9e2bbac3\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/61/9e/955ab1890f6cab231b1d756db63f36c711968a324296e0b649\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=9f2585c30df9021ceefd1ff5d4df6ef888a6ceb81401c7f0aef8c07e423e4ed2\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built optuna pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.0 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.3.0 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.2.1\n",
            "  Downloading transformers-4.2.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 14.9 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 56.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (3.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (4.11.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (4.64.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 53.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1) (2019.12.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.1) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.1) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.1) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=222df4bbe2cc9ced8f1e0974495b72d1670a89617905a1a4dffc362494e8a512\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.9.4 transformers-4.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyarabic\n",
        "!pip install emoji\n",
        "!pip install pystemmer\n",
        "!pip install optuna==2.3.0\n",
        "!pip install transformers==4.2.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AK1i5BGwgp6y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarabic.araby as ar\n",
        "\n",
        "import re , emoji, Stemmer, functools, operator, string\n",
        "import torch , optuna, gc, random, os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix, precision_score , recall_score\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from transformers.data.processors import SingleSentenceClassificationProcessor\n",
        "from transformers import Trainer , TrainingArguments\n",
        "from transformers.trainer_utils import EvaluationStrategy\n",
        "from transformers.data.processors.utils import InputFeatures\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import SpatialDropout1D, Conv1D, Bidirectional, LSTM, Dense, Input, Dropout, GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import itertools\n",
        "from numpy import loadtxt\n",
        "from keras.models import load_model\n",
        "\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.WARNING)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**the function of the preprocessing**"
      ],
      "metadata": {
        "id": "oEJtCCnxF05S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CXrG4tyVg2BH"
      },
      "outputs": [],
      "source": [
        "st =  Stemmer.Stemmer('arabic')\n",
        "def data_cleaning (x):\n",
        "    x = re.sub('@[^\\s]+', ' ', x)\n",
        "    x = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',x)\n",
        "    \n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                               u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U00002702-\\U000027B0\"\n",
        "                               u\"\\U000024C2-\\U0001F251\"\n",
        "                               u\"\\U0001f926-\\U0001f937\"\n",
        "                               u\"\\U00010000-\\U0010ffff\"\n",
        "                               u\"\\u2640-\\u2642\"\n",
        "                               u\"\\u2600-\\u2B55\"\n",
        "                               u\"\\u200d\"\n",
        "                               u\"\\u23cf\"\n",
        "                               u\"\\u23e9\"\n",
        "                               u\"\\u231a\"\n",
        "                               u\"\\ufe0f\"  # dingbats\n",
        "                               u\"\\u3030\"\"]+\", flags=re.UNICODE)\n",
        "    emoji_pattern.sub(r'', x)\n",
        "    \n",
        "    ar_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ#'''\n",
        "    en_punctuations = string.punctuation\n",
        "    punctuations = ar_punctuations + en_punctuations\n",
        "    x = x.translate(str.maketrans('', '', punctuations))\n",
        " \n",
        "    arabic_diacritics = re.compile(\"\"\" ّ    | # Tashdid\n",
        "                             َ    | # Fatha\n",
        "                             ً    | # Tanwin Fath\n",
        "                             ُ    | # Damma\n",
        "                             ٌ    | # Tanwin Damm\n",
        "                             ِ    | # Kasra\n",
        "                             ٍ    | # Tanwin Kasr\n",
        "                             ْ    | # Sukun\n",
        "                             ـ     # Tatwil/Kashida\n",
        "                         \"\"\", re.VERBOSE)\n",
        "    x = re.sub(arabic_diacritics, '', str(x)) \n",
        "    \n",
        "#     x = re.sub(\"[إأآا]\", \"ا\", x)\n",
        "#     x = re.sub(\"ى\", \"ي\", x)\n",
        "#     x = re.sub(\"ة\", \"ه\", x)\n",
        "#     x = re.sub(\"گ\", \"ك\", x)\n",
        "#     x = re.sub(r'(.)\\1+', r'\\1', x)\n",
        "    \n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Connecting to google drive**"
      ],
      "metadata": {
        "id": "EVp1l40LF4ST"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M90Q1oS7gsSZ",
        "outputId": "e3bb4b4f-b7d8-41e0-d952-4648ce668cd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " \n",
        "**Uploading the dataset**"
      ],
      "metadata": {
        "id": "rYj4pO6SF7oi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "Ad17M2Nug4uj",
        "outputId": "c461216b-ebf4-4d29-a155-d856d62de094"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   no Hotel name  rating    user type                   room type  \\\n",
              "0   2    فندق 72       2  مسافر منفرد  غرفة ديلوكس مزدوجة أو توأم   \n",
              "1   3    فندق 72       5          زوج  غرفة ديلوكس مزدوجة أو توأم   \n",
              "2  16    فندق 72       5          زوج                           -   \n",
              "\n",
              "            nights                                             review  \n",
              "0  أقمت ليلة واحدة                  “ممتاز”. النظافة والطاقم متعاون.   \n",
              "1  أقمت ليلة واحدة  استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...  \n",
              "2      أقمت ليلتين  استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61778895-7026-4fc4-995d-df5af20564e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>no</th>\n",
              "      <th>Hotel name</th>\n",
              "      <th>rating</th>\n",
              "      <th>user type</th>\n",
              "      <th>room type</th>\n",
              "      <th>nights</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>فندق 72</td>\n",
              "      <td>2</td>\n",
              "      <td>مسافر منفرد</td>\n",
              "      <td>غرفة ديلوكس مزدوجة أو توأم</td>\n",
              "      <td>أقمت ليلة واحدة</td>\n",
              "      <td>“ممتاز”. النظافة والطاقم متعاون.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>فندق 72</td>\n",
              "      <td>5</td>\n",
              "      <td>زوج</td>\n",
              "      <td>غرفة ديلوكس مزدوجة أو توأم</td>\n",
              "      <td>أقمت ليلة واحدة</td>\n",
              "      <td>استثنائي. سهولة إنهاء المعاملة في الاستقبال. ل...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>فندق 72</td>\n",
              "      <td>5</td>\n",
              "      <td>زوج</td>\n",
              "      <td>-</td>\n",
              "      <td>أقمت ليلتين</td>\n",
              "      <td>استثنائي. انصح بأختيار الاسويت و بالاخص غرفه ر...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61778895-7026-4fc4-995d-df5af20564e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61778895-7026-4fc4-995d-df5af20564e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61778895-7026-4fc4-995d-df5af20564e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "Text_Col_Train = \"review\"\n",
        "Sentiment_Col_Train = \"sentiment\"\n",
        "Train_Data_File = \"/content/gdrive/MyDrive/thesis/HARD.xlsx\"\n",
        "\n",
        "train_data = pd.DataFrame()\n",
        "\n",
        "train_data = pd.read_excel(Train_Data_File)\n",
        "\n",
        "train_data.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYS1dmN4iAAC",
        "outputId": "2cc4f8ba-46b8-4c54-9f7b-d5ec5405f317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2    38467\n",
            "4    26450\n",
            "5    26399\n",
            "1    14382\n",
            "Name: rating, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(train_data.rating.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **printing the fiels with missed values**\n"
      ],
      "metadata": {
        "id": "HpgFtw3sGAPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RQ-nVPciBfA",
        "outputId": "e08a48f1-1cb4-4dfd-a480-0edf57851342"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no            0\n",
              "Hotel name    0\n",
              "rating        0\n",
              "user type     0\n",
              "room type     0\n",
              "nights        0\n",
              "review        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**printing the number of the duplicated rows**"
      ],
      "metadata": {
        "id": "23bcD4j7GEEu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKaHo1VRiJAu",
        "outputId": "b53257e9-4eb8-4f7f-ff18-3cc67995a48d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On a  0 doublons dans Data.\n"
          ]
        }
      ],
      "source": [
        "print(\"On a  {} doublons dans Data.\".format(train_data.duplicated().sum()))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**checking the types of the fiels in the data**"
      ],
      "metadata": {
        "id": "CjowPRx5GJN_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IS1v1quRiUpY",
        "outputId": "7dc6a7a6-13a4-4749-9e44-7576cdbc316e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "no             int64\n",
              "Hotel name    object\n",
              "rating         int64\n",
              "user type     object\n",
              "room type     object\n",
              "nights        object\n",
              "review        object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**function for printing the pie**"
      ],
      "metadata": {
        "id": "NMygHTvjGL9_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8DKdjKkriZm2"
      },
      "outputs": [],
      "source": [
        "def pie(data,col):\n",
        "    labels = data[col].value_counts().keys().tolist()\n",
        "    n = len(labels)\n",
        "    if n==2:\n",
        "        colors = ['#66b3ff', '#fb3999']\n",
        "    elif n==3:\n",
        "        colors = ['#66b3ff', '#fb3999', '#ffcc99']\n",
        "    elif n==4:\n",
        "        colors = ['#66b3ff', '#fb3999', '#ffcc99',\"#66f3ff\"]\n",
        "    elif n==5:\n",
        "        colors = ['#66b3ff', '#fb3999', '#ffcc99',\"#66f3ff\",'#adcc99']\n",
        "    elif n==6:\n",
        "        colors = ['#66b3ff', '#fb3999', '#ffcc99',\"#66f3ff\",'#adcc99',\"#db7f23\"]\n",
        "    \n",
        "    fig1, f1 = plt.subplots()\n",
        "    f1.pie(data[col].value_counts(), labels=labels, colors = colors, autopct='%1.1f%%',shadow=False, startangle=60) \n",
        "    f1.axis('equal')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "def histo(data,col):\n",
        "    plt.figure(figsize = (10, 8))\n",
        "    sns.histplot(data=data, x=col, hue = data[col], fill=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Counting the % of each classe**"
      ],
      "metadata": {
        "id": "IOlO0XfgGPhh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3p4YWhmijD-",
        "outputId": "ec388aeb-b9f5-4296-f281-7f4203e9113d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    0.363933\n",
              "4    0.250241\n",
              "5    0.249759\n",
              "1    0.136067\n",
              "Name: rating, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_data.rating.value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Printing the distribution of the classes**"
      ],
      "metadata": {
        "id": "m3GW_F81GSke"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "c09JFYv2ipz7",
        "outputId": "8cc31884-67a1-47b0-c356-a40fc5be610e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pie(train_data, \"rating\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Repartitionning the data to 2 classes**"
      ],
      "metadata": {
        "id": "qSO5My9SGekC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9G1ai388SE7Q",
        "outputId": "408c4ae5-1fc2-45ab-d8e7-318f89a3806e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ],
      "source": [
        "positive_reviews = train_data[train_data[\"rating\"] > 3]\n",
        "positive_reviews[\"sentiment\"] = \"Positive\"\n",
        "\n",
        "negative_reviews = train_data[train_data[\"rating\"] < 3]\n",
        "negative_reviews[\"sentiment\"] = \"Negative\"\n",
        "\n",
        "train_data = pd.concat([positive_reviews, negative_reviews], ignore_index = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**preprocessing the reviews and printing the time spent & Deleting unused fields**"
      ],
      "metadata": {
        "id": "Tqfe_3bpGjkv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "YhiMCvb_i3ef",
        "outputId": "2ee6e410-c0aa-4eef-81e3-92432572330f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0   استثنائي سهولة إنهاء المعاملة في الاستقبال لاشيئ  Positive\n",
              "1  استثنائي انصح بأختيار الاسويت و بالاخص غرفه رق...  Positive\n",
              "2  جيد المكان جميل وهاديء كل شي جيد ونظيف بس كان ...  Positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6ff9613-475e-4ef3-82ee-f8055e379037\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>استثنائي سهولة إنهاء المعاملة في الاستقبال لاشيئ</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>استثنائي انصح بأختيار الاسويت و بالاخص غرفه رق...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>جيد المكان جميل وهاديء كل شي جيد ونظيف بس كان ...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6ff9613-475e-4ef3-82ee-f8055e379037')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6ff9613-475e-4ef3-82ee-f8055e379037 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6ff9613-475e-4ef3-82ee-f8055e379037');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Cleaning Training Data \n",
        "train_data[Text_Col_Train] = train_data[Text_Col_Train].apply(lambda x:   data_cleaning(str(x)))\n",
        "\n",
        "# Removing un-needed feilds\n",
        "train_data.drop(['no','Hotel name','rating','user type','room type','nights'], axis = 1, inplace = True)\n",
        "train_data.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spliting Data (Train , Evaluation)**"
      ],
      "metadata": {
        "id": "zLNDHgrPGnIc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzhBUcitjQw6",
        "outputId": "66bd3a65-1491-40fb-bbe8-d0f6f6a8f374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "Train set: \n",
            "Positive    42309\n",
            "Negative    42249\n",
            "Name: sentiment, dtype: int64\n",
            "---------------------------\n",
            "Evaluation set: \n",
            "Negative    10600\n",
            "Positive    10540\n",
            "Name: sentiment, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# First setting the max_len , will be useful later for BERT Model\n",
        "Extra_Len = 6 # an extra padding in length , found to be useful for increasing F-score\n",
        "Max_Len = train_data[Text_Col_Train].str.split().str.len().max() + Extra_Len\n",
        "print(Max_Len)\n",
        "\n",
        "#Spliting the Training data\n",
        "Test_Size = 0.20 \n",
        "                     \n",
        "Rand_Seed = 42 \n",
        "\n",
        "train_set, evaluation_set = train_test_split( train_data, test_size= Test_Size, random_state= Rand_Seed)\n",
        "\n",
        "y=pd.get_dummies(train_data.sentiment)\n",
        "\n",
        "train_set, X_test, y_train, y_test = train_test_split(train_data, y, test_size = 0.20, random_state = 42)\n",
        "\n",
        "print(\"Train set: \")\n",
        "print(train_set[Sentiment_Col_Train].value_counts())\n",
        "print(\"---------------------------\")\n",
        "print (\"Evaluation set: \")\n",
        "print (evaluation_set[Sentiment_Col_Train].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing BERTModel Classes**"
      ],
      "metadata": {
        "id": "cheTP6VyGqei"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "YaMR2DgTlfyZ"
      },
      "outputs": [],
      "source": [
        "Model_Used = \"UBC-NLP/MARBERT\"\n",
        "Task_Name = \"classification\"\n",
        "\n",
        "class Dataset:\n",
        "    def __init__(\n",
        "        self,\n",
        "        name,\n",
        "        train,\n",
        "        test,\n",
        "        label_list,\n",
        "    ):\n",
        "        self.name = name\n",
        "        self.train = train\n",
        "        self.test = test\n",
        "        self.label_list = label_list\n",
        "        \n",
        "class BERTModelDataset(Dataset):\n",
        "    def __init__(self, text, target, model_name, max_len, label_map):\n",
        "      super(BERTModelDataset).__init__()\n",
        "      self.text = text\n",
        "      self.target = target\n",
        "      self.tokenizer_name = model_name\n",
        "      self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "      self.max_len = max_len\n",
        "      self.label_map = label_map\n",
        "  \n",
        "    def __len__(self):\n",
        "      return len(self.text)\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "      text = str(self.text[item])\n",
        "      text = \" \".join(text.split())\n",
        "    \n",
        "      encoded_review = self.tokenizer.encode_plus(\n",
        "      text,\n",
        "      max_length= self.max_len,\n",
        "      add_special_tokens= True,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      truncation='longest_first',\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt'\n",
        "    )\n",
        "      input_ids = encoded_review['input_ids'].to(device)\n",
        "      attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "      return InputFeatures(input_ids=input_ids.flatten(), attention_mask=attention_mask.flatten(), label=self.label_map[self.target[item]])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining Needed Methods for training and evaluation**"
      ],
      "metadata": {
        "id": "tAvBT2dJGt01"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Fg5106Y8nCnb"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "  return AutoModelForSequenceClassification.from_pretrained(Model_Used, return_dict=True, num_labels=len(label_map))\n",
        "\n",
        "def compute_metrics(p): #p should be of type EvalPrediction\n",
        "  preds = np.argmax(p.predictions, axis=1)\n",
        "  assert len(preds) == len(p.label_ids)\n",
        "  print(classification_report(p.label_ids,preds))\n",
        "  #print(confusion_matrix(p.label_ids,preds))\n",
        "\n",
        "  macro_f1_pos_neg = f1_score(p.label_ids,preds,average='macro',labels=[1,2])\n",
        "  macro_f1 = f1_score(p.label_ids,preds,average='macro')\n",
        "  macro_precision = precision_score(p.label_ids,preds,average='macro')\n",
        "  macro_recall = recall_score(p.label_ids,preds,average='macro')\n",
        "  acc = accuracy_score(p.label_ids,preds)\n",
        "  return {\n",
        "      'macro_f1' : macro_f1,\n",
        "      'macro_f1_pos_neg' : macro_f1_pos_neg,  \n",
        "      'macro_precision': macro_precision,\n",
        "      'macro_recall': macro_recall,\n",
        "      'accuracy': acc\n",
        "  }\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build Train and Evaluation Datasets**"
      ],
      "metadata": {
        "id": "npKSMxfWHGKe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOVTp2IOnFzi",
        "outputId": "d3e9f89c-2719-40bf-9c0e-d617f827dc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Negative', 'Positive']\n",
            "Positive    42309\n",
            "Negative    42249\n",
            "Name: sentiment, dtype: int64\n",
            "{'Negative': 0, 'Positive': 1}\n"
          ]
        }
      ],
      "source": [
        "label_list = list(train_set[Sentiment_Col_Train].unique())\n",
        "\n",
        "print(label_list)\n",
        "print(train_set[Sentiment_Col_Train].value_counts())\n",
        "\n",
        "data_set = Dataset( \"LABR\", train_set, evaluation_set, label_list )\n",
        "\n",
        "label_map = { v:index for index, v in enumerate(label_list) }\n",
        "print(label_map)\n",
        "\n",
        "train_dataset = BERTModelDataset(train_set[Text_Col_Train].to_list(),\n",
        "                                 train_set[Sentiment_Col_Train].to_list(),Model_Used,Max_Len,label_map)\n",
        "\n",
        "evaluation_dataset = BERTModelDataset(evaluation_set[Text_Col_Train].to_list(),\n",
        "                                      evaluation_set[Sentiment_Col_Train].to_list(),Model_Used,Max_Len,label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Training Arguments**"
      ],
      "metadata": {
        "id": "GhEWYqCdHXHl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "N33NDyT3nLf9"
      },
      "outputs": [],
      "source": [
        "#define training arguments\n",
        "training_args = TrainingArguments(\"./train\")\n",
        "training_args.lr_scheduler_type = 'cosine'\n",
        "training_args.evaluate_during_training = True\n",
        "training_args.adam_epsilon =1e-8 \n",
        "training_args.learning_rate = 1.78255000000000001e-05 # use this with org data  \n",
        "training_args.fp16 = True\n",
        "training_args.per_device_train_batch_size = 16  \n",
        "training_args.per_device_eval_batch_size = 128 \n",
        "training_args.gradient_accumulation_steps = 2\n",
        "training_args.num_train_epochs= 2\n",
        "training_args.warmup_steps = 0 \n",
        "training_args.evaluation_strategy = EvaluationStrategy.EPOCH\n",
        "training_args.logging_steps = 200\n",
        "training_args.save_steps = 100000 \n",
        "training_args.seed = 42 \n",
        "training_args.disable_tqdm = False"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build The Trainer**"
      ],
      "metadata": {
        "id": "Ii8Llz5WHg3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WK78APTNnRnH",
        "outputId": "df87f3d3-6d4d-4f7f-d0d0-a50786c8660b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at UBC-NLP/MARBERT were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "42\n"
          ]
        }
      ],
      "source": [
        "training_args.dataloader_pin_memory = False\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "set_seed(Rand_Seed) \n",
        "\n",
        "trainer = Trainer(\n",
        "    model = model_init(),\n",
        "    args = training_args,\n",
        "    train_dataset = train_dataset,\n",
        "    eval_dataset= evaluation_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "print(training_args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "jsYgdL1ZHxAq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 942
        },
        "id": "QoWFJuHnnXLV",
        "outputId": "ce66e5d8-50fa-4499-a981-285d81aa784e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "512\n",
            "1.78255e-05\n",
            "1e-08\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='5284' max='5284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5284/5284 1:55:03, Epoch 1/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Macro F1</th>\n",
              "      <th>Macro F1 Pos Neg</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.130300</td>\n",
              "      <td>0.127983</td>\n",
              "      <td>0.959319</td>\n",
              "      <td>0.479667</td>\n",
              "      <td>0.959330</td>\n",
              "      <td>0.959328</td>\n",
              "      <td>0.959319</td>\n",
              "      <td>288.315100</td>\n",
              "      <td>73.323000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.114000</td>\n",
              "      <td>0.142033</td>\n",
              "      <td>0.961825</td>\n",
              "      <td>0.481023</td>\n",
              "      <td>0.961943</td>\n",
              "      <td>0.961850</td>\n",
              "      <td>0.961826</td>\n",
              "      <td>287.558900</td>\n",
              "      <td>73.515000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96     10600\n",
            "           1       0.96      0.96      0.96     10540\n",
            "\n",
            "    accuracy                           0.96     21140\n",
            "   macro avg       0.96      0.96      0.96     21140\n",
            "weighted avg       0.96      0.96      0.96     21140\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96     10600\n",
            "           1       0.95      0.97      0.96     10540\n",
            "\n",
            "    accuracy                           0.96     21140\n",
            "   macro avg       0.96      0.96      0.96     21140\n",
            "weighted avg       0.96      0.96      0.96     21140\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2143: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='166' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [166/166 04:46]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96     10600\n",
            "           1       0.95      0.97      0.96     10540\n",
            "\n",
            "    accuracy                           0.96     21140\n",
            "   macro avg       0.96      0.96      0.96     21140\n",
            "weighted avg       0.96      0.96      0.96     21140\n",
            "\n",
            "{'eval_loss': 0.14203259348869324, 'eval_macro_f1': 0.9618246300619384, 'eval_macro_f1_pos_neg': 0.48102337393594513, 'eval_macro_precision': 0.9619432519481768, 'eval_macro_recall': 0.9618501843829437, 'eval_accuracy': 0.9618259224219489, 'eval_runtime': 287.1875, 'eval_samples_per_second': 73.61, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        }
      ],
      "source": [
        "all_results = []\n",
        "\n",
        "print(Max_Len)\n",
        "print(training_args.learning_rate)\n",
        "print(training_args.adam_epsilon)\n",
        "print(training_args.warmup_steps)\n",
        "trainer.train()\n",
        "\n",
        "results = trainer.evaluate()\n",
        "all_results.append(results)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results**"
      ],
      "metadata": {
        "id": "12kEE-SWIP8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMhJISSPpuGC",
        "outputId": "dd80f5ce-874d-420e-b54f-2b4b3d622536"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'epoch': 2.0,\n",
              "  'eval_accuracy': 0.9618259224219489,\n",
              "  'eval_loss': 0.14203259348869324,\n",
              "  'eval_macro_f1': 0.9618246300619384,\n",
              "  'eval_macro_f1_pos_neg': 0.48102337393594513,\n",
              "  'eval_macro_precision': 0.9619432519481768,\n",
              "  'eval_macro_recall': 0.9618501843829437,\n",
              "  'eval_runtime': 287.1875,\n",
              "  'eval_samples_per_second': 73.61}]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "all_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aAwl1n0qqRx",
        "outputId": "c05cd5e6-20b3-4a58-c896-6f234f302319"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9618246300619384"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "from statistics import mean\n",
        "mean([x['eval_macro_f1'] for x in all_results])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Sentiment Analysis - MarBERT(Using HARD Dataset) -.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}